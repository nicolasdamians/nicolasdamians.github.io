---
layout: post
title: "M3T3 - ELK - Spanish Version"
date: 2024-05-15 10:25:00 
categories:
    - posts
tags:
    - Master
    - Home_work
    - M3
    - monitor
    - tools
    - es
---

### 

ÍNDICE DE CONTENIDOS

[**Enunciado de la tarea 3**](#enunciado-de-la-tarea)

[**Despliegue de Stack ELK 4**](#despliegue-de-stack-elk)

> [Proceso de instalación de ELK + Kibana
> 4](#proceso-de-instalación-de-elk-kibana)
>
> [Elastic 4](#elastic)
>
> [Kibana 6](#kibana)
>
> [Logstash 8](#logstash)
>
> [Input 10](#input)
>
> [Filtros 11](#filtros)
>
> [Output 14](#output)
>
> [Configuración del servicio logstash
> 15](#configuración-del-servicio-logstash)

[**Dashboards Kibana 15**](#dashboards-kibana)

# 

# 

# 

# 

# 

# 

# 

# 

# 

# 

# 

# 

# 

# 

# 

# 

# 

# Enunciado de la tarea

ELK se puede utilizar de diferentes formas:\
- Instalando las aplicaciones descargadas desde el repositorio de
elastic.co\
- Utilizando docker-compose para levantar los servicios
([[https://www.docker.elastic.co/]{.underline}](https://www.docker.elastic.co/))\
- Utilizando una instancia de Elastic Cloud\
- Simplemente descargando las aplicaciones y ejecutándose sin necesidad
de instalarlas

Esta actividad tiene el objetivo de interiorizar el funcionamiento de la
pila ELK monitorizando logs del sistema.

La tarea consiste y tiene un valor de:

\- Despliegue de ELK (10%)\
- Descripción del formato de los logs elegidos, indicando con un ejemplo
la estructura de una línea modelo (20 %)\
- Configuración de Logstash o beats utilizados (30%)\
- A partir de los datos ingestados, mostrar un dashboard de Kibana que
contenga al menos cuatro visualizaciones. Se proponen algunas de las
siguientes visualizaciones (40%):

◦ Número total de eventos.\
◦ Ficheros más habituales\
◦ Categorías más recurrentes\
◦ Etc.

En esta actividad se deberán usar, al menos, el input plugin file{}, el
filter plugin grok{} y el output plugin de elasticsearch{}.

# Despliegue de Stack ELK

El enfoque inicial que planteé fue desplegar y usar el Elastic Cloud,
cosa que me pareció extremadamente sencillo. Finalmente opte por
desplegar la siguiente infra en mi lab on prem:

![](media/image2.png){width="6.5in" height="3.3472222222222223in"}

La idea es dejar una VM con Logstash y otra con ELK + Kibana. Habrán dos
dispositivos físicos enviando mediante Syslog datos a Logstash, este los
enviará a ELK y Kibana los indexara y printara. Nota: Para este
ejercicio solamente exportare logs desde el Fortigate.

## Proceso de instalación de ELK + Kibana

[[https://www.elastic.co/guide/en/elasticsearch/reference/current/install-elasticsearch.html]{.underline}](https://www.elastic.co/guide/en/elasticsearch/reference/current/install-elasticsearch.html)

[[https://www.elastic.co/guide/en/kibana/current/deb.html]{.underline}](https://www.elastic.co/guide/en/kibana/current/deb.html)

### Elastic

Mediante apt instalamos elastic previo a añadir su PGP y repositorio,
tal como indica la guía adjunta.

![](media/image17.png){width="6.5in" height="2.2083333333333335in"}

Configuramos el daemon para que arranque con el OS:

![](media/image9.png){width="6.5in" height="1.1527777777777777in"}

Comprobamos que esté levantado:

![](media/image26.png){width="6.5in" height="2.013888888888889in"}

Configuramos de manera muy básica ELK:

![](media/image11.png){width="6.5in" height="1.8611111111111112in"}

(cambios realizados son las lineas '\<')

### Kibana

Instalamos mediante apt![](media/image20.png){width="6.5in"
height="1.4444444444444444in"}

Configuramos demonio, levantamos y hacemos BK de la config:

![](media/image22.png){width="6.5in" height="0.6111111111111112in"}

Copiamos el cert CA de Elastic a Kibana:

![](media/image3.png){width="6.5in" height="0.20833333333333334in"}

Reseteamos pass de kibana:\
![](media/image13.png){width="6.5in" height="0.3055555555555556in"}

Realizamos configuración básica de Kibana:

![](media/image8.png){width="6.5in" height="4.138888888888889in"}

Reseteamos el servicio de Kibana y comprobamos que levante
correctamente.

![](media/image15.png){width="6.07054571303587in"
height="3.8038199912510935in"}

## Logstash

Ref:
https://www.elastic.co/guide/en/logstash/current/installing-logstash.html

1.  Actualizar lista de paquetes y actualizarlos

2.  Instalar 'openjdk-8-jre'\
    root@k8s-1:\~# apt-get install openjdk-8-jre\
    ![](media/image23.png){width="6.5in" height="5.861111111111111in"}

3.  Instalar la Public Signing Key, agregar el repo e instalar Logstash
    mediante APT\
    ![](media/image24.png){width="6.5in" height="5.597222222222222in"}

### 

### 

### 

### 

### 

### Input

4.  Creamos un archivo de configuración exclusivo para el fortigate, nos
    vamos a basar sobre [[UDP input
    Plugin]{.underline}](https://www.elastic.co/guide/en/logstash/current/plugins-inputs-udp.html)
    y a sacar el output por consola\
    ![](media/image7.png){width="6.5in" height="2.6527777777777777in"}

5.  Configuramos el syslog en el Forti:\
    ![](media/image18.png){width="6.5in" height="3.5555555555555554in"}

6.  Levantamos logstash con el archivo de config creado en el paso
    anterior para ***[examinar los logs que nos va a pasar el Forti\
    ]{.underline}***![](media/image4.png){width="6.5in"
    height="1.5972222222222223in"}\[..\]\
    ![](media/image19.png){width="6.5in" height="3.138888888888889in"}

### Filtros

[[https://www.elastic.co/guide/en/logstash/current/plugins-filters-grok.html]{.underline}](https://www.elastic.co/guide/en/logstash/current/plugins-filters-grok.html)

7.  Copiamos un mensaje que contenga información del Forti para jugar
    con el Grok Debugger que podemos encontrar en Kibana.\
    ![](media/image21.png){width="6.5in" height="2.7083333333333335in"}\
    Explicación:\
    **%{SYSLOG5424PRI}\
    **Este es un patrón predefinido de Grok que corresponde a la
    prioridad de syslog en el formato RFC5424. Este formato incluye un
    número de prioridad encerrado entre \< y \>; en el ejemplo:
    \<189\>.\
    \
    **%{GREEDYDATA:message}**\
    Este es otro patrón predefinido de Grok. GREEDYDATA captura
    cualquier cantidad de caracteres hasta el final de la línea.\
    :message indica que todo lo que se capture con GREEDYDATA se
    almacenará en el campo llamado message.

8.  Borramos información que no interesa mediante mutate:\
    ![](media/image16.png){width="6.5in" height="3.7083333333333335in"}\
    ![](media/image12.png){width="6.5in" height="1.7777777777777777in"}

9.  Finalmente tras varias horas de prueba y error y de obtener
    diferentes fuentes de información el filtro queda así:\
    ![](media/image5.png){width="6.5in" height="6.75in"}\
    Usando KV borramos las contrabarras y agregamos un salto de línea.\
    Hecho una prueba con logdate y date, necesito más horas para
    desarrollar o debugear.\
    También encuentro útil convertir a Integer los bytes enviados y
    recibidos.

### Output

[[https://www.elastic.co/guide/en/logstash/current/plugins-outputs-elasticsearch.html]{.underline}](https://www.elastic.co/guide/en/logstash/current/plugins-outputs-elasticsearch.html)

![](media/image25.png){width="5.916666666666667in"
height="3.0729166666666665in"}

Definimos el output filter de elasticsearch, indicando el hosts, creando
un index, especificando user y pass de elastic, e indicamos que CA debe
usar (la de Elastic).

### Configuración del servicio logstash

root@k8s-1:\~# systemctl start logstash.service

También comentamos la línea del filtro de output 'stdout' ya que no es
necesario ver la salida por consola más.

# 

# Dashboards Kibana

Creamos un data view:

![](media/image14.png){width="6.5in" height="1.5694444444444444in"}

Una vez creado el data view, mediante Analytics -\> Discover es cuestión
de ir buscando la combinación de datos que resulte más interesante para
crear dashboards. Ejemplo:

![](media/image6.png){width="6.5in" height="3.5694444444444446in"}
